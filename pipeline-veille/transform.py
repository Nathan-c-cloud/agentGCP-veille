"""
Module de transformation de contenu - Phase TRANSFORM du pipeline ETL
D√©coupe le contenu en chunks s√©mantiques optimis√©s pour le RAG.
"""

from typing import List, Dict
from urllib.parse import urlparse
import re
import hashlib


class ContentChunker:
    """D√©coupe le contenu en morceaux s√©mantiques optimis√©s pour la recherche."""
    
    def __init__(
        self,
        chunk_size: int = 1500,
        chunk_overlap: int = 200,
        min_chunk_size: int = 100
    ):
        """
        Args:
            chunk_size: Taille cible d'un chunk en caract√®res
            chunk_overlap: Chevauchement entre chunks pour pr√©server le contexte
            min_chunk_size: Taille minimale d'un chunk (les plus petits sont ignor√©s)
        """
        self.chunk_size = chunk_size
        self.chunk_overlap = chunk_overlap
        self.min_chunk_size = min_chunk_size
    
    def _generer_chunk_id(self, source_url: str, index: int) -> str:
        """
        G√©n√®re un ID unique et stable pour un chunk.
        
        Args:
            source_url: URL source du document
            index: Index du chunk dans le document
            
        Returns:
            Un ID unique (ex: "F23570-chunk-0")
        """
        # Extraire l'identifiant de la page (ex: F23570, N24265)
        url_path = urlparse(source_url).path
        page_id = url_path.split('/')[-1] if url_path else "unknown"
        
        # Si pas d'ID clair, utiliser un hash de l'URL
        if not page_id or page_id == "unknown":
            page_id = hashlib.md5(source_url.encode()).hexdigest()[:8]
        
        return f"{page_id}-chunk-{index}"
    
    def _nettoyer_texte(self, texte: str) -> str:
        """
        Nettoie le texte en retirant les espaces multiples et lignes vides excessives.
        
        Args:
            texte: Le texte √† nettoyer
            
        Returns:
            Le texte nettoy√©
        """
        # Remplacer les espaces multiples par un seul espace
        texte = re.sub(r' +', ' ', texte)
        
        # Remplacer les sauts de ligne multiples par maximum 2
        texte = re.sub(r'\n{3,}', '\n\n', texte)
        
        return texte.strip()
    
    def _decouper_par_separateurs(self, texte: str) -> List[str]:
        """
        D√©coupe le texte en utilisant une hi√©rarchie de s√©parateurs.
        Essaie d'abord les paragraphes, puis les phrases, puis les caract√®res.
        
        Args:
            texte: Le texte √† d√©couper
            
        Returns:
            Liste de chunks de texte
        """
        # Hi√©rarchie de s√©parateurs (du plus s√©mantique au plus basique)
        separateurs = [
            "\n\n",      # Paragraphes
            "\n",        # Lignes
            ". ",        # Phrases
            "! ",        # Phrases exclamatives
            "? ",        # Phrases interrogatives
            "; ",        # Clauses
            ", ",        # Clauses courtes
            " ",         # Mots
        ]
        
        chunks = [texte]
        
        # Appliquer chaque s√©parateur jusqu'√† ce que tous les chunks soient assez petits
        for separateur in separateurs:
            nouveaux_chunks = []
            
            for chunk in chunks:
                if len(chunk) <= self.chunk_size:
                    # Ce chunk est d√©j√† assez petit
                    nouveaux_chunks.append(chunk)
                else:
                    # D√©couper ce chunk
                    parties = chunk.split(separateur)
                    
                    chunk_actuel = ""
                    for partie in parties:
                        # Ajouter le s√©parateur sauf pour le dernier √©l√©ment
                        partie_avec_sep = partie + separateur if partie != parties[-1] else partie
                        
                        if len(chunk_actuel) + len(partie_avec_sep) <= self.chunk_size:
                            chunk_actuel += partie_avec_sep
                        else:
                            if chunk_actuel:
                                nouveaux_chunks.append(chunk_actuel)
                            chunk_actuel = partie_avec_sep
                    
                    if chunk_actuel:
                        nouveaux_chunks.append(chunk_actuel)
            
            chunks = nouveaux_chunks
            
            # Si tous les chunks sont assez petits, on peut arr√™ter
            if all(len(c) <= self.chunk_size for c in chunks):
                break
        
        return chunks
    
    def _ajouter_chevauchement(self, chunks: List[str]) -> List[str]:
        """
        Ajoute un chevauchement entre les chunks pour pr√©server le contexte.
        
        Args:
            chunks: Liste de chunks sans chevauchement
            
        Returns:
            Liste de chunks avec chevauchement
        """
        if len(chunks) <= 1:
            return chunks
        
        chunks_avec_overlap = []
        
        for i, chunk in enumerate(chunks):
            chunk_final = chunk
            
            # Ajouter le contexte du chunk pr√©c√©dent (fin)
            if i > 0 and self.chunk_overlap > 0:
                chunk_precedent = chunks[i - 1]
                overlap_debut = chunk_precedent[-self.chunk_overlap:]
                chunk_final = overlap_debut + chunk_final
            
            chunks_avec_overlap.append(chunk_final)
        
        return chunks_avec_overlap
    
    def decouper_document(self, document: Dict) -> List[Dict]:
        """
        D√©coupe un document en chunks s√©mantiques.
        
        Args:
            document: Dictionnaire contenant au minimum:
                - contenu_brut: Le texte √† d√©couper
                - source_url: L'URL source
                - titre: Le titre du document
                Et optionnellement d'autres m√©tadonn√©es
                
        Returns:
            Liste de dictionnaires, chacun repr√©sentant un chunk avec ses m√©tadonn√©es
        """
        contenu = document.get('contenu_brut', '')
        if not contenu:
            print(f"  ‚ö†Ô∏è  Pas de contenu √† d√©couper pour {document.get('source_url', 'URL inconnue')}")
            return []
        
        # Nettoyer le texte
        contenu_propre = self._nettoyer_texte(contenu)
        
        # D√©couper en chunks
        chunks_texte = self._decouper_par_separateurs(contenu_propre)
        
        # Ajouter le chevauchement
        chunks_texte = self._ajouter_chevauchement(chunks_texte)
        
        # Filtrer les chunks trop petits
        chunks_texte = [c for c in chunks_texte if len(c.strip()) >= self.min_chunk_size]
        
        # Cr√©er les documents de chunks avec m√©tadonn√©es
        chunks_documents = []
        source_url = document.get('source_url', '')
        
        for i, chunk_texte in enumerate(chunks_texte):
            chunk_doc = {
                "chunk_id": self._generer_chunk_id(source_url, i),
                "chunk_index": i,
                "contenu": chunk_texte.strip(),
                "titre_source": document.get('titre', 'Sans titre'),
                "source_url": source_url,
                "date_publication_source": document.get('date_publication'),
                "auteur_source": document.get('auteur'),
                "hostname": document.get('hostname'),
                "taille_caracteres": len(chunk_texte.strip()),
            }
            chunks_documents.append(chunk_doc)
        
        print(f"  ‚úÇÔ∏è  Document d√©coup√© en {len(chunks_documents)} chunks (taille moyenne: {sum(len(c['contenu']) for c in chunks_documents) // len(chunks_documents) if chunks_documents else 0} caract√®res)")
        
        return chunks_documents
    
    def decouper_plusieurs_documents(self, documents: List[Dict]) -> List[Dict]:
        """
        D√©coupe plusieurs documents en chunks.
        
        Args:
            documents: Liste de documents √† d√©couper
            
        Returns:
            Liste de tous les chunks de tous les documents
        """
        tous_les_chunks = []
        total = len(documents)
        
        print(f"\n‚úÇÔ∏è  D√©coupage de {total} documents en chunks...")
        
        for i, document in enumerate(documents, 1):
            print(f"\n[{i}/{total}] {document.get('titre', 'Sans titre')[:60]}...")
            chunks = self.decouper_document(document)
            tous_les_chunks.extend(chunks)
        
        print(f"\n‚úÖ D√©coupage termin√© : {len(tous_les_chunks)} chunks cr√©√©s au total")
        print(f"   Taille moyenne : {sum(c['taille_caracteres'] for c in tous_les_chunks) // len(tous_les_chunks) if tous_les_chunks else 0} caract√®res")
        
        return tous_les_chunks


# Fonction utilitaire pour usage direct
def decouper_document(document: Dict, chunk_size: int = 1500) -> List[Dict]:
    """
    Fonction utilitaire pour d√©couper un seul document rapidement.
    
    Args:
        document: Le document √† d√©couper
        chunk_size: Taille cible des chunks
        
    Returns:
        Liste de chunks
    """
    chunker = ContentChunker(chunk_size=chunk_size)
    return chunker.decouper_document(document)


if __name__ == "__main__":
    # Test du module avec un document fictif
    document_test = {
        "titre": "La Taxe sur la Valeur Ajout√©e (TVA)",
        "contenu_brut": """La TVA est un imp√¥t indirect sur la consommation. Elle est pay√©e par le consommateur final mais collect√©e par les entreprises.

Le taux normal de TVA est de 20%. Il s'applique √† la majorit√© des ventes de biens et des prestations de services.

Le taux r√©duit de 10% s'applique notamment √† la restauration, aux travaux dans les logements anciens, et aux transports de voyageurs.

Le taux super-r√©duit de 5,5% concerne les produits alimentaires de premi√®re n√©cessit√©, l'√©nergie, les livres, et les √©quipements pour personnes handicap√©es.

Enfin, le taux particulier de 2,1% s'applique aux m√©dicaments remboursables par la S√©curit√© sociale et √† la presse.""",
        "source_url": "https://entreprendre.service-public.fr/vosdroits/F23570",
        "date_publication": "2024-01-15",
    }
    
    print("Test de d√©coupage sur un document fictif...")
    chunks = decouper_document(document_test, chunk_size=200)
    
    print("\n" + "="*80)
    print("R√âSULTAT DU TEST")
    print("="*80)
    for chunk in chunks:
        print(f"\nüìÑ Chunk {chunk['chunk_index']} (ID: {chunk['chunk_id']})")
        print(f"   Taille: {chunk['taille_caracteres']} caract√®res")
        print(f"   Contenu: {chunk['contenu'][:150]}...")
        print("-"*80)

